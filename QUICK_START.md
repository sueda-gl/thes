# Quick Start Guide - Fast Testing

## ğŸš€ Optimized for Fast Iteration

The default configuration is now optimized for **quick testing**:

### Default Settings (Fast Mode)
- **Agents:** 20 (instead of 100)
- **Steps:** 4 (instead of 10)
- **Campaign Launch:** Step 2 (instead of 3)
- **Concurrency:** 3 requests at a time
- **Max Tokens:** 200 per response

### Performance
- **Time:** ~2-3 minutes per run
- **Cost:** ~$0.10 per run
- **API Calls:** ~60-80 total

## ğŸ“Š Testing Progression

Follow this testing strategy:

### Phase 1: Minimal Test (Verify it works)
```
Agents: 10
Steps: 3
Campaign Launch: 2

Time: ~1 minute
Cost: ~$0.03
Purpose: Verify no errors
```

### Phase 2: Small Test (See patterns)
```
Agents: 20
Steps: 4
Campaign Launch: 2

Time: ~2-3 minutes
Cost: ~$0.10
Purpose: See if campaigns work
```

### Phase 3: Medium Test (First real data)
```
Agents: 50
Steps: 7
Campaign Launch: 3

Time: ~8 minutes
Cost: ~$0.40
Purpose: Get preliminary results
```

### Phase 4: Full Simulation (Thesis data)
```
Agents: 100
Steps: 10
Campaign Launch: 3

Time: ~15-20 minutes
Cost: ~$1.20
Purpose: Final results for thesis
```

## ğŸ¯ What Each Configuration Tests

### Why Start Small?

**10 agents, 3 steps:**
- âœ… Verifies API key works
- âœ… Tests all code paths
- âœ… Very cheap (~$0.03)
- âœ… Fast feedback
- âŒ Not enough data for statistics
- âŒ Results not meaningful

**20 agents, 4 steps (Default):**
- âœ… Cheap (~$0.10)
- âœ… Fast (~2-3 min)
- âœ… Enough to see patterns
- âš ï¸ Some statistical tests may fail (low N)
- âš ï¸ Results directional, not conclusive

**50 agents, 7 steps:**
- âœ… Reasonable cost (~$0.40)
- âœ… Moderate time (~8 min)
- âœ… Better statistical power
- âœ… Can identify trends
- âš ï¸ May need more for publication

**100 agents, 10 steps:**
- âœ… Full statistical power
- âœ… Publication-quality results
- âœ… Network effects visible
- âŒ More expensive (~$1.20)
- âŒ Takes longer (~20 min)

## ğŸ’¡ Recommended Testing Flow

**Day 1: Debug and verify**
1. Run 10 agents, 3 steps (verify no errors)
2. Run 20 agents, 4 steps (see if campaigns work)
3. Fix any issues you find

**Day 2: Collect preliminary data**
1. Run 50 agents, 7 steps (3 different seeds)
2. Check if results make sense
3. Verify metrics look reasonable

**Day 3: Final data collection**
1. Run 100 agents, 10 steps (5 different seeds)
2. Collect comprehensive data
3. Export for thesis analysis

**Total cost:** ~$0.15 + ~$1.20 + ~$6.00 = **~$7-8 for complete thesis**

## ğŸ› Current Bugs Fixed

All major bugs have been fixed:
- âœ… Campaign posts now appear in feeds
- âœ… Engagement tracking works properly
- âœ… Statistical tests handle edge cases
- âœ… Parser handles varied LLM responses
- âœ… Event loop issues resolved

## âš¡ Quick Commands

**Start Streamlit:**
```bash
cd /Users/suedagul/thes
source venv/bin/activate
streamlit run main.py
```

**Delete old database (fresh start):**
```bash
rm -f data/simulation.db
```

**Check current settings:**
```bash
cat config.py | grep "NUM_AGENTS\|SIMULATION_STEPS"
```

## ğŸ“ˆ Success Indicators

**Good test run:**
```
STEP 2/4
  ğŸ¯ CAMPAIGN INJECTION
  âœ“ Hope campaign â†’ 10 agents
  âœ“ Fear campaign â†’ 10 agents
  
  ğŸ‘€ OBSERVATION PHASE
  âœ“ 45 total observations  â† Should be > 0
  
  ğŸ§  DECISION PHASE
  Actions: {'like': 3, 'comment': 5, 'post': 2}  â† Mixed actions
  
âœ“ Simulation complete!
âœ“ Cost: $0.10
```

**Warning signs:**
```
âš ï¸  0 observations after campaign  â† Campaigns not in feeds
âš ï¸  Actions: {'none': 20}  â† No engagement at all
âš ï¸  Cost: $0.00  â† LLM not being called
```

## ğŸ“ For Your Thesis

**Testing phase (now):** Use 20 agents, 4 steps
**Data collection (later):** Use 100 agents, 10 steps

This gives you:
- Fast iteration during development
- Full data when you're ready
- Cost-effective approach
- Good scientific rigor

**You're all set for fast iteration testing! ğŸš€**

